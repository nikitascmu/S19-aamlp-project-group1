ldat = lung %>% tbl_df()
ldat  # censorship is 2, not censored is 1
km = Surv(ldat$time, ldat$status==2) %>%
(function(x) survfit(x ~ 1, data=ldat))(.)  # drop rows that have NAs
# Kaplan-Meier curve
plot(km, xlab= "Days",ylab="P(survive)", mark.time=T)
km
### Cox model
cm = Surv(ldat$time, ldat$status==2) %>%
(function(x) coxph(x ~ age + sex +
meal.cal + wt.loss, data=ldat))(.)   #coxph is the cox proportional hazards; regressing time to event on age/gender/caloric intake
cm
### Regularized Cox model
library(glmnet)
lm = ldat %>% na.omit() %>%   #remove any rows for which there are missing values
(function(x) glmnet(x %>% select(-time,-status) %>%
as.data.frame() %>% as.matrix(),
Surv(x$time, x$status==2),
family="cox"))(.)
coef(lm, s=0.1) # spare solution where many feature coefficients are zero, so want to do L1 regularization (or already did?)
dev.new(0)
dev.new()
dat = data.frame(x=c(2, 3), y=c(0,0 ))
# Kaplan-Meier curve
plot(km, xlab= "Days",ylab="P(survive)", mark.time=T)
# toy example
dat = data.frame(x=c(25, 55, 60, 65, rep(70,6)), y=c(0, 1, 0, 1, rep(0,6))) # 0 is not censored, 1 is censored
model = Surv(dat$x, dat$y)  # y is binary whether censorship event happened or not; median survival time is NA because p(survive) does not drop below 0.5
survfit(model ~ 1, data=dat) %>% plot(mark.time=T, xlab="Years", ylab="p(survive)")
dat
?sSurv
?Surv
# toy example
dat = data.frame(x=c(25, 55, 60, 65, rep(70,6)), y=c(0, 1, 0, 1, rep(0,6))) # 0 is alive, 1 is dead
model = Surv(dat$x, dat$y)  # y is binary whether censorship event happened or not; median survival time is NA because p(survive) does not drop below 0.5
survfit(model ~ 1, data=dat) %>% plot(mark.time=T, xlab="Years", ylab="p(survive)")
survfit(model ~ 1, data=dat) %>% summary()
# real data
?lung
ldat = lung %>% tbl_df()
ldat  # censorship is 2, not censored is 1
km = Surv(ldat$time, ldat$status==2) %>%
(function(x) survfit(x ~ 1, data=ldat))(.)  # drop rows that have NAs
# Kaplan-Meier curve
plot(km, xlab= "Days",ylab="P(survive)", mark.time=T)
# toy example
dat = data.frame(x=c(25, 55, 60, 65, rep(70,6)), y=c(0, 1, 0, 1, rep(0,6))) # 0 is alive, 1 is dead
model = Surv(dat$x, dat$y)  # y is binary whether censorship event happened or not; median survival time is NA because p(survive) does not drop below 0.5
survfit(model ~ 1, data=dat) %>% plot(mark.time=T, xlab="Years", ylab="p(survive)")
dat = data.frame(x=c(1, 2, 3, 4, 5, 7, 8), y=c(0, 1, 1, 0, 0, 0, 0)) # 0 is alive, 1 is dead
model = Surv(dat$x, dat$y)  # y is binary whether censorship event happened or not; median survival time is NA because p(survive) does not drop below 0.5
survfit(model ~ 1, data=dat) %>% plot(mark.time=T, xlab="Years", ylab="p(survive)")
library(DataExplorer)
library(DataExplorer)
install.packages("DataExplorer")
library(DataExplorer)
install.packages("DataExplorer")
install.packages("corrplot")
library(DataExplorer)
library(ggplot2)
library(dplyr)
source("http://pcwww.liv.ac.uk/~william/R/crosstab.r")
library(corrplot)
library(data.table)
final_data <- read.csv("final_data.csv")
dat <- fread("final_data.csv") %>% as_tibble()
table(final_data$od_type)
table(final_data$od_year)
#ggplot(final_data, aes(as.factor(od_type),patch_count )) + geom_point() + labs(y = "Patch count", x = "opioid overdose")
ggplot(final_data, aes(as.factor(od_type),age )) + geom_point() + labs(y = "Patch count", x = "opioid overdose")
final_data_df <- final_data %>%
mutate(mme_group = ifelse(avg_mme %in% 1:99 ,"1.<100",
ifelse(avg_mme %in% 100:249 ,"2.100-249",
ifelse(avg_mme %in% 250:999 ,"3.250-999",
ifelse(avg_mme %in% 1000:4999 ,"4.1000-4999","5.>5000+")))))
crosstab(final_data, row.vars = "most_presc_drug",col.vars = "od_type", type = "f", addmargins = FALSE)
crosstab(final_data_df, row.vars = "mme_group",col.vars = "od_type", type = "f", addmargins = FALSE)
crosstab(final_data, row.vars = "race",col.vars = "od_type", type = "f", addmargins = FALSE)
crosstab(final_data, row.vars = "cohort",col.vars = "od_type", type = "f", addmargins = FALSE)
crosstab(final_data, row.vars = "most_dose_form",col.vars = "od_type", type = "f", addmargins = FALSE)
rm(final_data_df)
final_data <- group_category(data = final_data, feature = "most_presc_drug", threshold = 0.002, update = TRUE) %>%
group_category(feature = "most_dose_form", threshold = 0.0002, update = TRUE)
crosstab(final_data, row.vars = "most_presc_drug",col.vars = "od_type", type = "f", addmargins = FALSE)
crosstab(final_data, row.vars = "most_dose_form",col.vars = "od_type", type = "f", addmargins = FALSE)
#correlation matrix between numerical variables
corr_data_num <- final_data[,c(4,5,6,7,8,9,10,11,12,18,20,21,22,24,25,26,27,30,31)]
res <- cor(corr_data_num)
corrplot(res, type = "upper", order = "hclust", tl.col = "black", tl.srt = 45)
library(ggpubr)
install.packages("ggpubr")
library(ggpubr)
c1 <- ggplot(final_data, aes(avg_mme)) +geom_histogram(fill="#336B87",breaks=c(seq(100,6000, by=150)))
c2 <- ggplot(final_data, aes(median_mme)) +geom_histogram(fill="#336B87",breaks=c(seq(100,6000, by=150)))
c3 <- ggplot(final_data, aes(mode_mme)) + geom_histogram(fill="#336B87",breaks=c(seq(100,6000, by=150)))
ggarrange(c1,c2,c3,nrow=3,ncol=1)
rm(list=c('c1','c2','c3'))
final_data$target <- NULL
final_data$target[final_data$od_type=='No Overdose'] <- 0
final_data$target[final_data$od_type=='Non-Opiate Overdose'] <- 0
final_data$target[final_data$od_type=='Opiate Overdose'] <- 1
final_data <- final_data %>% select(-c('avg_mme','mode_mme','od_date','od_year','od_type','od_month','PERSON_ID'))
#dummifying data to create dummy categorical variables
final_df <- dummify(final_data)
# Multivariate logistic regression
# 50-50 split
dat_scrambled <- dat[sample(1:nrow(dat)),]
dat_train <- dat_scrambled[1:(dim(dat_scrambled)[1]/2),]
dat_test <- dat_scrambled[-(1:(dim(dat_scrambled)[1]/2)),]
dat_binary_odtype <- dat
dat_binary_odtype$od_type[which(dat_binary_odtype$od_type=="No Overdose")] <- 0
dat_binary_odtype$od_type[which(dat_binary_odtype$od_type=="Non-Opiate Overdose")] <- 0
dat_binary_odtype$od_type[which(dat_binary_odtype$od_type=="Opiate Overdose")] <- 1
# Predicting "Opiate Overdose" vs. no overdose or non-opiate overdose based on total_cr_drug_cases
lr = with(dat_train, glm(od_type=="Opiate Overdose" ~ total_cr_drug_cases, family = binomial("logit")))
lr %>% summary()    # estimates are the data coefficients; intercept = B0; each after is a B for the dummy variable; stars give the level of significance of the coefficients; all values are compared to a reference value (b was the reference value here); "values" can also be called "indicator values"; extract the Beta-hats
lr %>% str()
lr %>% summary() %>% coef()
predictions = data.frame(preds=(lr %>% predict(dat_test, type="response"))) # get predictions on new data; "response" gives predicted probabilities
library(ggplot2)
dat_test %>%
select(od_type) %>%
bind_cols(predictions) %>%
table() %>%
data.frame() %>% as_tibble() %>%
group_by(preds) %>%
mutate(testfreq = sum(Freq)) %>%
mutate(testfreq = Freq/testfreq) %>%
ungroup() %>% filter(od_type=='Opiate Overdose') %>%
select(preds,testfreq) %>%   # this model is relatively well-calibrated; if predictions perfectly calibrated, y=x
mutate_all(as.character) %>%
mutate_all(as.numeric) %>%
ggplot(data=., aes(x=preds, y=testfreq)) + geom_point() + geom_abline(slope=1)
library(ROCR)
columns_for_ROC =  # columns: predictions, labels
dat_test %>%
select(od_type) %>%
bind_cols(predictions) %>% mutate(od_type=od_type=="Opiate Overdose")   # true labels, and their predictions
# plot it:
prediction(predictions=columns_for_ROC$preds,
labels=columns_for_ROC$od_type) %>%
performance("tpr", "fpr") %>% plot()
# performance("auc")  # swap out to get AUC
final_df
View(final_df)
library(ROCR)
columns_for_ROC =  # columns: predictions, labels
dat_test %>%
select(od_type) %>%
bind_cols(predictions) %>% mutate(od_type=od_type=="Opiate Overdose")   # true labels, and their predictions
# plot it:
prediction(predictions=columns_for_ROC$preds,
labels=columns_for_ROC$od_type) %>%
performance("tpr", "fpr") %>% plot()
# performance("auc")  # swap out to get AUC
# Random forest
library(randomForest)
dat_scrambled <- as_tibble(dat_scrambled)
# NAs introduced by coercion; col 14, 15, 16 (119428)
data_fac <- dat_binary_odtype %>% mutate_if(is.character, as.factor)
forest = randomForest(formula = as.factor(data_fac$od_type) ~ .,
data=data_fac[, -c(14:16)] %>% filter(!is.na(od_type)))
library(keras)
# Neural net
trans <- function(x){
return (log(1+x))
}
#performing a 50%/50% split
smp_size <- floor(0.5 * nrow(final_df))
set.seed(1)
train_indices <- sample(seq_len(nrow(final_df)),size=smp_size)
ytrain <- to_categorical(final_df$target[train_indices]) %>% as.matrix()
#logistic regression
smp_size <- floor(0.5 * nrow(final_df))
set.seed(1)
train_indices <- sample(seq_len(nrow(final_df)),size=smp_size)
xtrain <- final_df[train_indices,]
xtest <- final_df[-train_indices,]
xtrain$target <- factor(xtrain$target)
xtest$target <- factor(xtest$target)
model_logistic <- glm (target~., data=xtrain, family = binomial,control = list(maxit = 50))
## Predict the Values
predict_logistic <- predict(model_logistic, xtest, type = 'response')
## Create Confusion Matrix
table(xtest$target, predict_logistic > 0.5)
library(DMwR)
install.packages("DMwR")
library(DMwR)
#logistic with sampling
set.seed(1)
balanced.data <- SMOTE(target ~., xtrain, perc.over = 1500, k = 5, perc.under = 400)
as.data.frame(table(balanced.data$target))
model_logistic_balanced <- glm (target~.-race_White -gender_No.Data.and.Other -most_presc_drug_TRAMADOL-most_dose_form_PILL,
data=balanced.data, family = binomial,control = list(maxit = 50))
## Predict the Values
pred_logistic_balanced <- predict(model_logistic_balanced, xtest, type = 'response')
## Create Confusion Matrix
table(xtest$target, pred_logistic_balanced > 0.5)
?heatmap.2
heatmap.2(arr[[i]], dendrogram ='none',
Rowv=FALSE, Colv=FALSE, col=c(colorRampPalette(c(blue_colors[1], blue_colors[max(arr[[i]], na.rm=T)*100]))(max(arr[[i]], na.rm=T)*100)),
key=FALSE, keysize=1.0, symkey=FALSE, density.info='none',
trace='none', colsep=1:10,rowsep=1:10,
sepcolor='white', sepwidth=c(0.05,0.05),
margins=c(0.01,0.01),
scale="none", cexRow=1,cexCol=1,
labRow=rownames(arr[[i]]), labCol=colnames(arr[[i]]),
cellnote=arr[[i]], notecex=0.5, notecol="black", na.color="#F8F8F8",
# labCol = colnames(arr[[i]]),
#cellnote=NULL, notecex=0, notecol=NULL, na.color=NULL,
lmat=rbind( c(0, 3), c(2,1), c(0,4) ), lhei=c(0.25, 1, 0.25 )
)
?pheatmap
library(pheatmap)
?pheatmap
library(DataExplorer)
library(ggplot2)
library(dplyr)
source("http://pcwww.liv.ac.uk/~william/R/crosstab.r")
library(corrplot)
library(data.table)
final_data <- read.csv("final_data.csv")
dat <- fread("final_data.csv") %>% as_tibble()
table(final_data$od_type)
final_data_df <- final_data %>%
mutate(mme_group = ifelse(avg_mme %in% 1:99 ,"1.<100",
ifelse(avg_mme %in% 100:249 ,"2.100-249",
ifelse(avg_mme %in% 250:999 ,"3.250-999",
ifelse(avg_mme %in% 1000:4999 ,"4.1000-4999","5.>5000+")))))
crosstab(final_data, row.vars = "most_presc_drug",col.vars = "od_type", type = "f", addmargins = FALSE)
crosstab(final_data_df, row.vars = "mme_group",col.vars = "od_type", type = "f", addmargins = FALSE)
crosstab(final_data, row.vars = "race",col.vars = "od_type", type = "f", addmargins = FALSE)
crosstab(final_data, row.vars = "cohort",col.vars = "od_type", type = "f", addmargins = FALSE)
crosstab(final_data, row.vars = "most_dose_form",col.vars = "od_type", type = "f", addmargins = FALSE)
rm(final_data_df)
final_data <- group_category(data = final_data, feature = "most_presc_drug", threshold = 0.002, update = TRUE) %>%
group_category(feature = "most_dose_form", threshold = 0.0002, update = TRUE)
crosstab(final_data, row.vars = "most_presc_drug",col.vars = "od_type", type = "f", addmargins = FALSE)
crosstab(final_data, row.vars = "most_dose_form",col.vars = "od_type", type = "f", addmargins = FALSE)
#correlation matrix between numerical variables
corr_data_num <- final_data[,c(4,5,6,7,8,9,10,11,12,18,20,21,22,24,25,26,27,30,31)]
res <- cor(corr_data_num)
corrplot(res, type = "upper", order = "hclust", tl.col = "black", tl.srt = 45)
library(ggpubr)
c1 <- ggplot(final_data, aes(avg_mme)) +geom_histogram(fill="#336B87",breaks=c(seq(100,6000, by=150)))
c2 <- ggplot(final_data, aes(median_mme)) +geom_histogram(fill="#336B87",breaks=c(seq(100,6000, by=150)))
c3 <- ggplot(final_data, aes(mode_mme)) + geom_histogram(fill="#336B87",breaks=c(seq(100,6000, by=150)))
ggarrange(c1,c2,c3,nrow=3,ncol=1)
rm(list=c('c1','c2','c3'))
final_data$target <- NULL
final_data$target[final_data$od_type=='No Overdose'] <- 0
final_data$target[final_data$od_type=='Non-Opiate Overdose'] <- 0
final_data$target[final_data$od_type=='Opiate Overdose'] <- 1
final_data <- final_data %>% select(-c('avg_mme','mode_mme','od_date','od_year','od_type','od_month','PERSON_ID'))
trans <- function(x){
return (log(1+x))
}
#dummifying data to create dummy categorical variables
final_df <- final_data %>% select(-c(target))
final_df <- dummify(final_df)
final_df <- final_df  %>% mutate_all(funs(trans))
final_df$target <- final_data$target
#logistic regression
smp_size <- floor(0.5 * nrow(final_df))
set.seed(1)
train_indices <- sample(seq_len(nrow(final_df)),size=smp_size)
xtrain <- final_df[train_indices,]
xtest <- final_df[-train_indices,]
xtrain$target <- factor(xtrain$target)
xtest$target <- factor(xtest$target)
model_logistic <- glm (target~., data=xtrain, family = binomial,control = list(maxit = 50))
## Predict the Values
predict_logistic <- predict(model_logistic, xtest, type = 'response')
## Create Confusion Matrix
table(xtest$target, predict_logistic > 0.4)
library(parallel)
library(doParallel)
install.packages("doParallel")
library(parallel)
library(doParallel)
library(caret)
install.packages("caret")
library(parallel)
library(doParallel)
library(caret)
library(parallel)
library(doParallel)
library(caret)
library(parallel)
library(doParallel)
library(caret)
library(DMwR)
options(scipen=999)
#logistic with Over sampling
set.seed(1)
balanced.data <- SMOTE(target ~., xtrain, perc.over = 500, k = 5, perc.under = 500)
as.data.frame(table(balanced.data$target))
cluster <- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
registerDoParallel(cluster)
fitControl <- trainControl(method = "cv", number = 5, allowParallel = TRUE)
fit <- train(target ~ ., method="rf",data=balanced.data,trControl = fitControl)
var.imp <- varImp(fit)
plot(var.imp,top=15)
balanced.data
# Boosting
library(ada)
model_ada = ada(formula = target ~ .,data=balanced.data ,iter=10)
pred_ada <- predict(model_ada,xtest,type = 'prob')
table(pred_ada[,2]>0.2,xtest$target)
library(keras)
# Neural net
balanced.data2 <- SMOTE(target ~., xtrain, perc.over = 4800, k = 5, perc.under = 2400)
y_train <- as.numeric(balanced.data2$target) %>% as.matrix()
y_test <- as.numeric(xtest$target) %>% as.matrix()
x_train <- balanced.data2 %>% select(-c(target)) %>% as.matrix()
library(dplyr)
library(keras)
# Neural net
balanced.data2 <- SMOTE(target ~., xtrain, perc.over = 4800, k = 5, perc.under = 2400)
y_train <- as.numeric(balanced.data2$target) %>% as.matrix()
y_test <- as.numeric(xtest$target) %>% as.matrix()
x_train <- balanced.data2 %>% select(-c(target)) %>% as.matrix()
x_test <- xtest %>% select(-c(target)) %>% as.matrix()
model_nn <- keras_model_sequential()
model_nn <- model_nn %>%
layer_dense(units = 256, activation = 'tanh', input_shape = c(20)) %>%
layer_dropout(rate = 0.4) %>%
layer_dense( units= 256, kernel_initializer = "uniform", activation = "tanh") %>%
layer_dropout(0.1) %>%
layer_dense(units = 64, activation = 'relu') %>%
layer_dropout(rate = 0.3) %>%
layer_dense(units = 1, activation = 'softmax')
model_nn %>% compile(
loss = 'binary_crossentropy',
optimizer = optimizer_rmsprop(),
metrics = c('accuracy')
)
history <- model_nn %>% fit(
x_train, y_train,
epochs = 50, batch_size = 128,
validation_split = 0.2
)
library(pROC)
final_data$target <- NULL
final_data$target[final_data$od_type=='No Overdose'] <- 0
final_data$target <- NULL
final_data$target[final_data$od_type=='No Overdose'] <- 0
final_data$target <- NULL
final_data$target[final_data$od_type=='No Overdose'] <- 0
library(ggpubr)
c1 <- ggplot(final_data, aes(avg_mme)) +geom_histogram(fill="#336B87",breaks=c(seq(100,6000, by=150)))
c2 <- ggplot(final_data, aes(median_mme)) +geom_histogram(fill="#336B87",breaks=c(seq(100,6000, by=150)))
c3 <- ggplot(final_data, aes(mode_mme)) + geom_histogram(fill="#336B87",breaks=c(seq(100,6000, by=150)))
ggarrange(c1,c2,c3,nrow=3,ncol=1)
library(DataExplorer)
library(ggplot2)
library(dplyr)
source("http://pcwww.liv.ac.uk/~william/R/crosstab.r")
library(corrplot)
library(data.table)
final_data <- read.csv("final_data.csv")
dat <- fread("final_data.csv") %>% as_tibble()
table(final_data$od_type)
final_data_df <- final_data %>%
mutate(mme_group = ifelse(avg_mme %in% 1:99 ,"1.<100",
ifelse(avg_mme %in% 100:249 ,"2.100-249",
ifelse(avg_mme %in% 250:999 ,"3.250-999",
ifelse(avg_mme %in% 1000:4999 ,"4.1000-4999","5.>5000+")))))
crosstab(final_data, row.vars = "most_presc_drug",col.vars = "od_type", type = "f", addmargins = FALSE)
crosstab(final_data_df, row.vars = "mme_group",col.vars = "od_type", type = "f", addmargins = FALSE)
crosstab(final_data, row.vars = "race",col.vars = "od_type", type = "f", addmargins = FALSE)
crosstab(final_data, row.vars = "cohort",col.vars = "od_type", type = "f", addmargins = FALSE)
crosstab(final_data, row.vars = "most_dose_form",col.vars = "od_type", type = "f", addmargins = FALSE)
rm(final_data_df)
final_data <- group_category(data = final_data, feature = "most_presc_drug", threshold = 0.002, update = TRUE) %>%
group_category(feature = "most_dose_form", threshold = 0.0002, update = TRUE)
crosstab(final_data, row.vars = "most_presc_drug",col.vars = "od_type", type = "f", addmargins = FALSE)
crosstab(final_data, row.vars = "most_dose_form",col.vars = "od_type", type = "f", addmargins = FALSE)
#correlation matrix between numerical variables
corr_data_num <- final_data[,c(4,5,6,7,8,9,10,11,12,18,20,21,22,24,25,26,27,30,31)]
res <- cor(corr_data_num)
corrplot(res, type = "upper", order = "hclust", tl.col = "black", tl.srt = 45)
library(ggpubr)
c1 <- ggplot(final_data, aes(avg_mme)) +geom_histogram(fill="#336B87",breaks=c(seq(100,6000, by=150)))
c2 <- ggplot(final_data, aes(median_mme)) +geom_histogram(fill="#336B87",breaks=c(seq(100,6000, by=150)))
c3 <- ggplot(final_data, aes(mode_mme)) + geom_histogram(fill="#336B87",breaks=c(seq(100,6000, by=150)))
ggarrange(c1,c2,c3,nrow=3,ncol=1)
rm(list=c('c1','c2','c3'))
final_data$target <- NULL
final_data$target[final_data$od_type=='No Overdose'] <- 0
final_data$target[final_data$od_type=='Non-Opiate Overdose'] <- 0
final_data$target[final_data$od_type=='Opiate Overdose'] <- 1
final_data <- final_data %>% select(-c('avg_mme','mode_mme','od_date','od_year','od_type','od_month','PERSON_ID'))
trans <- function(x){
return (log(1+x))
}
#dummifying data to create dummy categorical variables
final_df <- final_data %>% select(-c(target))
final_df <- dummify(final_df)
final_df <- final_df  %>% mutate_all(funs(trans))
final_df$target <- final_data$target
#logistic regression
smp_size <- floor(0.5 * nrow(final_df))
set.seed(1)
train_indices <- sample(seq_len(nrow(final_df)),size=smp_size)
xtrain <- final_df[train_indices,]
xtest <- final_df[-train_indices,]
xtrain$target <- factor(xtrain$target)
xtest$target <- factor(xtest$target)
model_logistic <- glm (target~., data=xtrain, family = binomial,control = list(maxit = 50))
## Predict the Values
predict_logistic <- predict(model_logistic, xtest, type = 'response')
## Create Confusion Matrix
table(xtest$target, predict_logistic > 0.4)
library(parallel)
library(doParallel)
library(caret)
cols_to_select = c("tram_count","total_da","race_White","total_cr_drug_cases","median_mme","total_cr_cases",
"race_Black.African.American","avg_dispensed","most_presc_drug_OXYMORPHONE.HCL","gender_Male","gender_Female",
"avg_supply","age","total_mh","total_acj","pill_count",
"num_presc","hydrobit_count","oxy_count","most_presc_drug_HYDROCODONE.BITARTRATE","target")
xtrain <- xtrain[,c(cols_to_select)]
xtest <- xtest[,c(cols_to_select)]
balanced.data <- balanced.data[,c(cols_to_select)]
fitControl <- trainControl(method = "repeatedcv",number = 5,repeats = 3)
library(DMwR)
options(scipen=999)
library(caret)
library("caret")
install.packages("caret")
install.packages("caret")
library(parallel)
library(doParallel)
library(caret)
set.seed(1)
balanced.data <- SMOTE(target ~., xtrain, perc.over = 500, k = 5, perc.under = 500)
as.data.frame(table(balanced.data$target))
cluster <- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
registerDoParallel(cluster)
fitControl <- trainControl(method = "cv", number = 5, allowParallel = TRUE)
fit <- train(target ~ ., method="rf",data=balanced.data,trControl = fitControl)
var.imp <- varImp(fit)
plot(var.imp,top=15)
cols_to_select = c("tram_count","total_da","race_White","total_cr_drug_cases","median_mme","total_cr_cases",
"race_Black.African.American","avg_dispensed","most_presc_drug_OXYMORPHONE.HCL","gender_Male","gender_Female",
"avg_supply","age","total_mh","total_acj","pill_count",
"num_presc","hydrobit_count","oxy_count","most_presc_drug_HYDROCODONE.BITARTRATE","target")
xtrain <- xtrain[,c(cols_to_select)]
xtest <- xtest[,c(cols_to_select)]
balanced.data <- balanced.data[,c(cols_to_select)]
fitControl <- trainControl(method = "repeatedcv",number = 5,repeats = 3)
library(glmnet)
set.seed(123)
y = balanced.data$target %>% as.matrix()
x = balanced.data %>% select(-c(target))   %>% as.matrix()
cv.lasso <- cv.glmnet(x, y, alpha = 0.1, family = "binomial",nfolds=10,type.measure = "auc")
model_ridge <- glmnet(x, y, alpha = 1, family = "binomial",lambda = cv.lasso$lambda.min)
# Make predictions on the test data
x.test <- xtest %>% select(-c(target)) %>% as.matrix()
pred_ridge <- model_ridge %>% predict(newx = x.test)
table(pred_ridge>0.2,xtest$target)
fitControl <- trainControl(method = "cv", number = 5, allowParallel = TRUE)
library(gbm)
set.seed(123)
fitControl = trainControl(method="cv", number=5, returnResamp = "all",allowParallel = TRUE)
# Boosting
library(ada)
model_ada = ada(formula = target ~ .,data=balanced.data ,iter=10)
pred_ada <- predict(model_ada,xtest,type = 'prob')
table(pred_ada[,2]>0.2,xtest$target)
library(keras)
# Neural net
balanced.data2 <- SMOTE(target ~., xtrain, perc.over = 4800, k = 5, perc.under = 2400)
y_train <- as.numeric(balanced.data2$target) %>% as.matrix()
y_test <- as.numeric(xtest$target) %>% as.matrix()
x_train <- balanced.data2 %>% select(-c(target)) %>% as.matrix()
x_test <- xtest %>% select(-c(target)) %>% as.matrix()
model_nn <- keras_model_sequential()
model_nn <- model_nn %>%
layer_dense(units = 256, activation = 'tanh', input_shape = c(20)) %>%
layer_dropout(rate = 0.4) %>%
layer_dense( units= 256, kernel_initializer = "uniform", activation = "tanh") %>%
layer_dropout(0.1) %>%
layer_dense(units = 64, activation = 'relu') %>%
layer_dropout(rate = 0.3) %>%
layer_dense(units = 1, activation = 'softmax')
model_nn %>% compile(
loss = 'binary_crossentropy',
optimizer = optimizer_rmsprop(),
metrics = c('accuracy')
)
history <- model_nn %>% fit(
x_train, y_train,
epochs = 50, batch_size = 128,
validation_split = 0.2
)
pred_model_nn = model_nn %>% predict(x_test)
table(pred_model_nn,xtest$target)
install.packages("pROC")
library(pROC)
roc(xtest$target,pred_logistic_cv,plot=TRUE,legacy.axes=TRUE, col="#377eb8",print.auc=TRUE,percent = TRUE,print.auc.y=60,
xlab="false positive percentage",ylab="true positive percentage")
roc(xtest$target,pred_logistic_cv,plot=TRUE,legacy.axes=TRUE, col="#377eb8",print.auc=TRUE,percent = TRUE,print.auc.y=60,
xlab="false positive percentage",ylab="true positive percentage")
plot.roc(xtest$target,pred_ridge, col="#4daf4a",print.auc=TRUE,add=TRUE,percent=TRUE,print.auc.y=50)
plot.roc(xtest$target,pred_rf, col="#FF420E",print.auc=TRUE,add=TRUE,percent=TRUE,print.auc.y=40)
plot.roc(xtest$target,pred_gbm$'1', col="#FFBB00",print.auc=TRUE,add=TRUE,percent=TRUE,print.auc.y=30)
plot.roc(xtest$target,pred_ada[,2], col="#763626",print.auc=TRUE,add=TRUE,percent=TRUE,print.auc.y=20)
plot.new()
plot.roc(xtest$target,pred_ada[,2], col="#763626",print.auc=TRUE,add=TRUE,percent=TRUE,print.auc.y=20)
plot.roc(xtest$target,pred_model_nn, col="#375E97",print.auc=TRUE,add=TRUE,percent=TRUE,print.auc.y=10)
library(pROC)
