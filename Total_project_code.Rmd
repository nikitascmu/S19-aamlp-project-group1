---
title: "ML Pipeline Project Code"
author: "Lauren Rost, Mridul Singh Gangawar, Nikita Setia"
date: "March 19, 2019"
output:
  html_document: default
  pdf_document: default
---

# Loading Necessary Files and Packages

```{r, message=FALSE, warning=FALSE}
#--- Loading helper files 
loadlibs = function(libs) {
  for(lib in libs) {
    class(lib)
    if(!do.call(require,as.list(lib))) {install.packages(lib)}
    do.call(require,as.list(lib))
  }
}
libs = c("tidyr","magrittr","purrr","dplyr","stringr","readr","data.table", "mice", 
         "randomForest", "ada", "gbm", "caret", "e1071", "ROCR", "ggplot2", "readxl",
         "survival", "fastDummies", "DataExplorer", "ggplot2", "corrplot", "ggpubr", 
         "parallel", "doParallel","DMwR", "glmnet", "pROC", "keras", "tibble")

loadlibs(libs)

mode_fun <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}

#--- setting global decimal print setting
options(scipen=4)
source("http://pcwww.liv.ac.uk/~william/R/crosstab.r")

prog = fread("program_activity.csv") %>% as_tibble() 
dem = fread("demographic.csv") %>% as_tibble() 
presc = fread("opiate_prescription_fills.csv") %>% as_tibble()

```

# Summarizing the Demographic Dataset
```{r, message=FALSE, warning=FALSE}

# summarizing the demographic dataset
summary(dem %>% mutate_if(is.character, as.factor))

```

## Data Cleaning: Dealing with Missing Race and Gender Values in the Demographic Dataset

```{r, message=FALSE, warning=FALSE}

# dealing with missing data for RACE and GENDER

# dealing with missingness by allowing it to be its own category - because most likely MNAR
dem$RACE[which(grepl("No Data", dem$RACE))] = "No Data and Other"

# merging native hawaiian/pacific islander + no data = no data and other because the former is too small
dem$RACE[which(grepl("Native Hawaiian", dem$RACE))] = "No Data and Other"

# dealing with missingness by allowing it to be its own category - because most likely MNAR
dem$GENDER[which(grepl("No Data", dem$GENDER))] = "No Data and Other"

# merging transgendered male to female and no data = no data and other because former is too small
dem$GENDER[which(grepl("Transgendered", dem$GENDER))] = "No Data and Other"

# renaming for cleanliness and summarizing the clean demographic dataset
dem = dem %>% rename("race"=RACE, "gender"=GENDER)
summary(dem %>% mutate_if(is.character, as.factor))
```

# Summarizing the Program Dataset
```{r, message=FALSE, warning=FALSE}

# summarizing the program data
summary(prog)

```

Observations:

* No missing values in the program data 
* Overdose date and opiate overdose has NAs for individuals who have not overdosed, so that is meaningful and not actually missing

## Cleaning Outcome Variable in Program Dataset
```{r, message=FALSE, warning=FALSE}

# separating overdose data into year and month
prog = prog %>% separate(OVERDOSE_DATE, c("OVERDOSE_YEAR", "OVERDOSE_MONTH"), remove=FALSE, sep=4)

# creating the outcome variable
prog$OPIATE_OVERDOSE[which(grepl(0, prog$OPIATE_OVERDOSE))] = "Non-Opiate Overdose"
prog$OPIATE_OVERDOSE[which(grepl(1, prog$OPIATE_OVERDOSE))] = "Opiate Overdose"
prog$OPIATE_OVERDOSE[which(is.na(prog$OPIATE_OVERDOSE))] = "No Overdose"

# summarizing the cleaned program dataset
summary(prog %>% mutate_if(is.character, as.factor))


```

## Data Pre-processing: Creating Variables from the Program Dataset
```{r, message=FALSE, warning=FALSE}

# establishing the number of times an individual has used DHS programs
times_used = prog %>% group_by(PERSON_ID) %>% select(YEAR, MONTH) %>% summarise(times_used = max(sequence(n())))

# creating new predictor variables from the program dataset
prog_summary = prog %>% group_by(PERSON_ID) %>% summarise(total_cyfchild = sum(CYFCHILD),
                                                          total_cyfparent = sum(CYFPARENT),
                                                          total_mh = sum(MH),
                                                          total_da = sum(DA),
                                                          total_rx = sum(RX),
                                                          total_acj = sum(ACJ),
                                                          total_cr_cases = sum(MDJS_CR_CASES),
                                                          total_cr_drug_cases = sum(MDJS_CR_DRUG_CASES),
                                                          cohort = min(YEAR),
                                                          od_date = max(OVERDOSE_DATE), 
                                                          od_year = max(OVERDOSE_YEAR), 
                                                          od_month = max(OVERDOSE_MONTH), 
                                                          od_type = max(OPIATE_OVERDOSE))
```

# Summarizing the Prescription Dataset
```{r, message=FALSE, warning=FALSE}

# summarizing the prescription dataset
summary(presc %>% mutate_if(is.character, as.factor))

```

## Creating a Clean Version of the Age Variable from the Prescription Dataset
```{r, message=FALSE, warning=FALSE}

# obtaining the min, max, and mean age of an individual from the prescription dataset
age_df = presc %>% group_by(PERSON_ID) %>% summarise(min_age = min(AGE), max_age = max(AGE), mean_age = round(mean(AGE)))

# if age is less 0, then take the max age else take min age, 
# if max age is still less than 0 then replace with 999 (considered missing)
age_df = age_df %>% group_by(PERSON_ID) %>% mutate(age_clean = if_else(min_age<0, max_age, min_age)) %>%
  mutate(age_clean = if_else(age_clean<0, 999, age_clean))

# replace ages greater than 99 with NA (considered missing)
age_df$age_clean[which(age_df$age_clean>99)] = NA
age_df$age = age_df$age_clean

# for missing ages, take the median age across the entire set of individuals
age_df$age[which(is.na(age_df$age_clean))] = median(age_df$age_clean, na.rm=TRUE)

# summarizing the cleaned age predictor variable
summary(age_df)
```

## Data Cleaning for Prescription Dataset
```{r, message=FALSE, warning=FALSE}

# extracting drug strength from label name (better version)
presc$drug_strength <- str_extract(presc$LABEL_NAME, "[0-9].*")

# drug strength indicated that these are oral solutions per 5ML, so made this change manually
presc$drug_strength[which(grepl('ORAL SOLUTION', presc$extract_strength))] <- "5-325/5ML"

# naloxone's drug strength was missing, so updated manually
presc$drug_strength[which(grepl('NALOXONE', presc$LABEL_NAME))] <- "50MG-0.5MG"

# taking values from the original drug strength column if the newly created one has missing values
presc = presc %>% mutate(drug_strength = if_else(is.na(drug_strength), DRUG_STRENGTH, drug_strength))

# creating a new column 'num_strength' that keeps only numeric values from 'drug_strength'
presc$num_strength <- str_extract(presc$drug_strength, "[0-9]*.*[0-9]")

# extracting only the opioid strength from the drug strength column
# we need this to calculate the MME
# converted the opioid strength standard format, ex: to per 1 ML in oral solution cases as opposed to 5 ML
presc <- separate(presc, num_strength, c("opioid_strength", "compound_strength"), sep = '-')
presc <- separate(presc, opioid_strength, c("opioid", "divisor"), sep = '/')
presc$opioid <- str_extract(presc$opioid, "[0-9]*.*[0-9]")
presc <- separate(presc, compound_strength, c("compound", "divisor2"), sep = '/')
presc = presc %>% mutate(divisor = if_else(is.na(divisor), divisor2, divisor))
presc = presc %>% select(-divisor2)
presc = presc %>% mutate(opioid = if_else(is.na(compound), opioid, if_else(opioid>compound, compound, opioid)))
presc$divisor[which(is.na(presc$divisor))] = 1
presc$compound[which(is.na(presc$compound))] = 1
presc = presc %>% mutate(opioid_converted = as.numeric(opioid)/as.numeric(divisor))

# creating a new column with the conversion factor associated with the drug name and dosage form
presc <- presc %>% 
  mutate(conversion_factor = 
    if_else(grepl('BUPRENORPHINE', GENERIC_NAME) & grepl('PATCH', DOSAGE_FORM_DESC), 12.6, 
    if_else(grepl('BUPRENORPHINE', GENERIC_NAME) & grepl('AMPUL', DOSAGE_FORM_DESC), 30,
    if_else(grepl('BUTORPHANOL', GENERIC_NAME), 7,
    if_else(grepl('CODEINE', GENERIC_NAME), 0.15,
    if_else(grepl('DIHYDROCODEINE BITARTRATE', GENERIC_NAME), 0.25,
    if_else(grepl('OPIUM', GENERIC_NAME), 1,
    if_else(grepl('FENTANYL', GENERIC_NAME) & grepl('TABLET', DOSAGE_FORM_DESC), 0.13,
    if_else(grepl('FENTANYL', GENERIC_NAME) & grepl('LOZENGE', DOSAGE_FORM_DESC), 0.13,
    if_else(grepl('FENTANYL', GENERIC_NAME) & grepl('PATCH', DOSAGE_FORM_DESC), 7.2,
    if_else(grepl('NALBUPHINE', GENERIC_NAME), 1,
    if_else(grepl('FENTANYL CITRATE', GENERIC_NAME), 0.13,
    if_else(grepl('HYDROCODONE', GENERIC_NAME), 1,
    if_else(grepl('HYDROMORPHONE', GENERIC_NAME), 4,
    if_else(grepl('LEVORPHANOL TARTRATE', GENERIC_NAME), 11,
    if_else(grepl('MEPERIDINE', GENERIC_NAME), 0.1,
    if_else(grepl('METHADONE', GENERIC_NAME) & opioid_converted<=20, 4, 
    if_else(grepl('METHADONE', GENERIC_NAME) & opioid_converted>20, 8, 
    if_else(grepl('MORPHINE', GENERIC_NAME), 1, 
    if_else(grepl('OXYCODONE', GENERIC_NAME), 1.5, 
    if_else(grepl('OXYMORPHONE', GENERIC_NAME), 3,
    if_else(grepl('PENTAZOCINE', GENERIC_NAME), 0.37,
    if_else(grepl('TAPENTADOL', GENERIC_NAME), 0.4,
    if_else(grepl('TRAMADOL', GENERIC_NAME), 0.1, 0))))))))))))))))))))))))

# stripping the drug name down to common terms to lower the number of categories
presc <- presc %>% 
  mutate(generic_name = 
    if_else(grepl('DIHYDROCODEINE BITARTR', presc$GENERIC_NAME), 'DIHYDROCODEINE BITARTRATE', 
    if_else(grepl('BUPRENORPHINE', presc$GENERIC_NAME), 'BUPRENORPHINE',
    if_else(grepl('HYDROCODONE BITARTRAT', presc$GENERIC_NAME), 'HYDROCODONE BITARTRATE',
    if_else(grepl('MORPHINE SULFATE', presc$GENERIC_NAME), 'MORPHINE SULFATE',
    if_else(grepl('OXYCODONE', presc$GENERIC_NAME), 'OXYCODONE', 
    if_else(grepl('PENTAZOCINE', presc$GENERIC_NAME), 'PENTAZOCINE',
    if_else(grepl('TRAMADOL', presc$GENERIC_NAME), 'TRAMADOL',
    if_else(grepl('CODEINE PHOSPHATE', presc$GENERIC_NAME), 'CODEINE PHOSPHATE',
    if_else(grepl('OPIUM/BELLADONNA', presc$GENERIC_NAME), 'OPIUM/BELLADONNA', 
    if_else(grepl('FENTANYL', presc$GENERIC_NAME), 'FENTANYL',
    if_else(grepl('HYDROMORPHONE', presc$GENERIC_NAME), 'HYDROMORPHONE', 
    if_else(grepl('MEPERIDINE', presc$GENERIC_NAME), 'MEPERIDINE', GENERIC_NAME
    )))))))))))))

# stripping the dosage form down to common terms to lower the number of categories
presc <- presc %>% 
  mutate(dosage_form = 
    if_else(grepl('TABLET', presc$DOSAGE_FORM_DESC), 'PILL', 
    if_else(grepl('VIAL', presc$DOSAGE_FORM_DESC), 'VIAL',
    if_else(grepl('SYRINGE', presc$DOSAGE_FORM_DESC), 'VIAL',
    if_else(grepl('CAPSULE', presc$DOSAGE_FORM_DESC), 'PILL', 
    if_else(grepl('PATCH', presc$DOSAGE_FORM_DESC), 'PATCH',
    if_else(grepl('LOZENGE', presc$DOSAGE_FORM_DESC), 'LOZENGE',
    if_else(grepl('AMPUL', presc$DOSAGE_FORM_DESC), 'AMPUL',
    if_else(grepl('SPRAY', presc$DOSAGE_FORM_DESC), 'SPRAY',
    if_else(grepl('SOLUTION', presc$DOSAGE_FORM_DESC), 'LIQUID',
    if_else(grepl('LIQUID', presc$DOSAGE_FORM_DESC), 'LIQUID',
    if_else(grepl('CONCENTRATE', presc$DOSAGE_FORM_DESC), 'LIQUID',
    if_else(grepl('SUPPOSITORY', presc$DOSAGE_FORM_DESC), 'SUPPOSITORY', 'NA'
    )))))))))))))

# cleaning the days supply variable in the prescription dataset
loop_values = presc %>% group_by(generic_name, dosage_form) %>% summarise(count = n())

generics = loop_values[[1]]
dosages = loop_values[[2]]

min_supply_vec=rep(0, length(generics))
max_supply_vec=rep(0, length(generics))
min_dispensed_vec=rep(0, length(generics))
max_dispensed_vec=rep(0, length(generics))

# looping over each drug name and dosage type to determine the minimum and maximum days supply for that combination

for (i in 1:length(generics)){
  presc_subset = presc %>% filter(generic_name==generics[i] & dosage_form==dosages[i])
  min_supply_vec[i]=round(quantile(presc_subset$DAYS_SUPPLY , probs=seq(0, 1, by=0.005))[[2]])
  max_supply_vec[i]=round(quantile(presc_subset$DAYS_SUPPLY, probs=seq(0, 1, by=0.005))[[200]])
  
  min_dispensed_vec[i]=round(quantile(presc_subset$DISPENSED_QTY , probs=seq(0, 1, by=0.005))[[5]])
  max_dispensed_vec[i]=round(quantile(presc_subset$DISPENSED_QTY, probs=seq(0, 1, by=0.005))[[195]])
}

min_supply_vec = min_supply_vec %>% as.data.frame()
min_supply_vec = min_supply_vec %>% rename(min_supply_val = ".")
max_supply_vec = max_supply_vec %>% as.data.frame()
max_supply_vec = max_supply_vec %>% rename(max_supply_val = ".")

min_dispensed_vec = min_dispensed_vec %>% as.data.frame()
min_dispensed_vec = min_dispensed_vec %>% rename(min_dispensed_val = ".")
max_dispensed_vec = max_dispensed_vec %>% as.data.frame()
max_dispensed_vec = max_dispensed_vec %>% rename(max_dispensed_val = ".")

values = bind_cols(loop_values, min_supply_vec)
values = bind_cols(values, max_supply_vec)
values = bind_cols(values, min_dispensed_vec)
values = bind_cols(values, max_dispensed_vec)
values = values %>% select(-count)

presc = merge(presc, values, all.x = TRUE, key=c("generic_name, dosage_form"))

# cleaning days supply variable such that it is not lower than minimum supply value or greater than maximum supply value
# for that combination of drug name and dosage form
# this helps us deal with missing or extreme days supply values

presc = presc %>% mutate(days_supply = if_else(DAYS_SUPPLY<min_supply_val, as.integer(min_supply_val), 
                                           if_else(DAYS_SUPPLY>max_supply_val, as.integer(max_supply_val),
                                                   as.integer(DAYS_SUPPLY))))

presc = presc %>% mutate(dispensed_qty = if_else(DISPENSED_QTY<min_dispensed_val,
                                                       as.integer(min_dispensed_val), 
                                           if_else(DISPENSED_QTY>max_dispensed_val, 
                                                   as.integer(max_dispensed_val),
                                                   as.integer(DISPENSED_QTY))))

# creating a new variable -- mme
presc$mme <- round((presc$opioid_converted*presc$dispensed_qty*presc$conversion_factor)/presc$days_supply,2)

```

## Data Pre-processing: Creating Variables from the Cleaned Prescription Dataset

```{r, warning=FALSE, message=FALSE}

presc_summary = presc %>% group_by(PERSON_ID) %>% summarise(num_presc = n(), 
                                            most_presc_drug = mode_fun(generic_name),
                                            oxy_count = sum(grepl('OXYCODONE', generic_name)),
                                            tram_count = sum(grepl('TRAMADOL', generic_name)),
                                            hydrobit_count = sum(grepl('HYDROCODONE BITARTRATE', generic_name)),
                                            most_dose_form = mode_fun(dosage_form),
                                            pill_count = sum(grepl('PILL', dosage_form)),
                                            patch_count = sum(grepl('PATCH', dosage_form)),
                                            liquid_count = sum(grepl('LIQUID', dosage_form)),
                                            avg_mme = round(mean(mme)),
                                            median_mme = round(median(mme)),
                                            mode_mme = round(mode_fun(mme)),
                                            avg_supply = round(mean(days_supply)),
                                            avg_dispensed = round(mean(dispensed_qty)))
```

# Creating & Summarizing Final Dataset 
```{r, warning=FALSE, message=FALSE}

# merging cleaned demographic dataset with the newly creating features from program and prescription datasets
final_data = merge(dem, age_df %>% select(PERSON_ID, age), all.x = TRUE, all.y = TRUE, key="PERSON_ID")
final_data = merge(final_data, prog_summary, all.x = TRUE, all.y = TRUE, key="PERSON_ID")
final_data = merge(final_data, presc_summary, all.x = TRUE, all.y = TRUE, key="PERSON_ID")

# summarizing the final dataset
summary(final_data %>% mutate_if(is.character, as.factor))

```


## Additional Pre-Processing Prior to Machine Learning Analysis
```{r, message=FALSE, warning=FALSE}

table(final_data$od_type)

final_data_df <- final_data %>% 
        mutate(mme_group = ifelse(avg_mme %in% 1:99 ,"Group 1: <100",
                           ifelse(avg_mme %in% 100:249 ,"Group 2: 100-249", 
                           ifelse(avg_mme %in% 250:999 ,"Group 3: 250-999",
                           ifelse(avg_mme %in% 1000:4999 ,"Group 4: 1000-4999","Group 5: >5000+")))))

crosstab(final_data, row.vars = "most_presc_drug",col.vars = "od_type", type = "f", addmargins = FALSE)
crosstab(final_data_df, row.vars = "mme_group",col.vars = "od_type", type = "f", addmargins = FALSE)
crosstab(final_data, row.vars = "race",col.vars = "od_type", type = "f", addmargins = FALSE)
crosstab(final_data, row.vars = "cohort",col.vars = "od_type", type = "f", addmargins = FALSE)
crosstab(final_data, row.vars = "most_dose_form",col.vars = "od_type", type = "f", addmargins = FALSE)

rm(final_data_df)
```

Some drugs and dosage form counts have very few counts so there is no need to keep them as a separate category. Here we create a separate category for "Other" in which we combine all such categories.

```{r, message=FALSE, warning=FALSE}
final_data <- group_category(data = final_data, feature = "most_presc_drug", threshold = 0.002, update = TRUE) %>%
            group_category(feature = "most_dose_form", threshold = 0.0002, update = TRUE)

crosstab(final_data, row.vars = "most_presc_drug",col.vars = "od_type", type = "f", addmargins = FALSE)
crosstab(final_data, row.vars = "most_dose_form",col.vars = "od_type", type = "f", addmargins = FALSE)
```


```{r pressure, echo=FALSE, message=FALSE, warning=FALSE}
#correlation matrix between numerical variables

corr_data_num <- final_data[,c(4,5,6,7,8,9,10,11,12,18,20,21,22,24,25,26,27,30,31)]
res <- cor(corr_data_num)
corrplot(res, type = "upper", order = "hclust", tl.col = "black", tl.srt = 45)

```

```{r, message=FALSE, warning=FALSE}
#checking distribution of median_mme, mode_mme, average_mme

c1 <- ggplot(final_data, aes(avg_mme)) + labs(x="Average Morphine Milligram Equivalents (MME)", y="Count") + geom_histogram(fill="#336B87",breaks=c(seq(100,6000, by=150))) + ggtitle("Average MME Frequency Distribution")

c2 <- ggplot(final_data, aes(median_mme)) + labs(x="Median MME", y="Count") + 
  geom_histogram(fill="#336B87",breaks=c(seq(100,6000, by=150))) + ggtitle("Median MME Frequency Distribution")

c3 <- ggplot(final_data, aes(mode_mme)) + labs(x="Mode MME", y="Count") + 
  geom_histogram(fill="#336B87",breaks=c(seq(100,6000, by=150))) + ggtitle("Mode MME Frequency Distribution")

ggarrange(c1,c2,c3,nrow=3,ncol=1)
rm(list=c('c1','c2','c3'))
```

median_mme looks normal and less skewed. We will be using median_mme for prediction purpose. Also, we remove columns that are related to overdose date, for this column is a proxy for the target variable and is not available in the future dataset. 

```{r, message=FALSE, warning=FALSE}

final_data$target <- NULL
final_data$target[final_data$od_type=='No Overdose'] <- 0
final_data$target[final_data$od_type=='Non-Opiate Overdose'] <- 0
final_data$target[final_data$od_type=='Opiate Overdose'] <- 1

#removing columns which are not fit for prediction purpose
final_data <- final_data %>% select(-c('avg_mme','mode_mme','od_date','od_year','od_type','od_month','PERSON_ID'))

#transforming data using log transformation
trans <- function(x){
  return (log(1+x))
}


#dummifying data to create dummy categorical variables
final_df <- final_data %>% select(-c(target))
final_df <- dummify(final_df)
final_df <- final_df  %>% mutate_all(funs(trans))
final_df$target <- final_data$target

```

# Machine Learning Analysis

## Multivariate Logistic Regression
```{r, message=FALSE, warning=FALSE}

#splitting train and testing set (50% ratio)
smp_size <- floor(0.5 * nrow(final_df))
set.seed(1)
train_indices <- sample(seq_len(nrow(final_df)),size=smp_size)

xtrain <- final_df[train_indices,]
xtest <- final_df[-train_indices,] 

xtrain$target <- factor(xtrain$target)
xtest$target <- factor(xtest$target)

model_logistic <- glm (target~., data=xtrain, family = binomial,control = list(maxit = 50))

## Predict the Values
predict_logistic <- predict(model_logistic, xtest, type = 'response')

## Create Confusion Matrix
table(xtest$target, predict_logistic > 0.4)
```

Due to the fact that we were not able to capture a single opioid overdose case with logistic regression, we attempt to identify opioid overdose cases using SMOTE (Synthetic Minority Oversampling Technique).

## Logistic Regression with Oversampling

```{r, message=FALSE, warning=FALSE}
options(scipen=999)

#performing Oversampling to generate synthetic data

set.seed(1)
balanced.data <- SMOTE(target ~., xtrain, perc.over = 500, k = 5, perc.under = 500)
as.data.frame(table(balanced.data$target))

cluster <- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
registerDoParallel(cluster)


#instead of training models on all the columns, we are identifying important columns using random forest 
fitControl <- trainControl(method = "cv", number = 5, allowParallel = TRUE)

fit <- train(target ~ ., method="rf",data=balanced.data,trControl = fitControl)

var.imp <- varImp(fit)
plot(var.imp,top=15)
```


## Multivariate Logistic Regression on Selected Features (using Cross-Validation)

```{r, message=FALSE, warning=FALSE}

#selecting columns which turns out to be important in random forest

cols_to_select = c("tram_count","total_da","race_White","total_cr_drug_cases","median_mme","total_cr_cases",
                   "race_Black.African.American","avg_dispensed","most_presc_drug_OXYMORPHONE.HCL","gender_Male","gender_Female",
                   "avg_supply","age","total_mh","total_acj","pill_count",
                   "num_presc","hydrobit_count","oxy_count","most_presc_drug_HYDROCODONE.BITARTRATE","target")

xtrain <- xtrain[,c(cols_to_select)]
xtest <- xtest[,c(cols_to_select)]
balanced.data <- balanced.data[,c(cols_to_select)]

#fitting our first model - logistic regression 

fitControl <- trainControl(method = "repeatedcv",number = 5,repeats = 5)

model_logistic_cv <- train(target ~ ., data = balanced.data, method = "glm",family = binomial(link = "logit"),
                          trControl = fitControl)


#predicted values for testdata:
pred_logistic_cv <- predict(model_logistic_cv$finalModel,xtest,type = 'response')

#test with confusion matrix
table(pred_logistic_cv>0.4,xtest$target)
```

## Ridge Regression (using Cross-Validation)

```{r, message=FALSE, warning=FALSE}
set.seed(123) 

y = balanced.data$target %>% as.matrix()
x = balanced.data %>% select(-c(target))   %>% as.matrix()

cv.lasso <- cv.glmnet(x, y, alpha = 0.1, family = "binomial",nfolds=10,type.measure = "auc")
model_ridge <- glmnet(x, y, alpha = 1, family = "binomial",lambda = cv.lasso$lambda.min)

# Make predictions on the test data
x.test <- xtest %>% select(-c(target)) %>% as.matrix()
pred_ridge <- model_ridge %>% predict(newx = x.test)

table(pred_ridge>0.2,xtest$target)
```

## Random forest (using Cross-Validation)

```{r, message=FALSE, warning=FALSE}

fitControl <- trainControl(method = "cv", number = 10, allowParallel = TRUE)

model_rf <- train(target ~ ., method="rf",data=balanced.data,trControl = fitControl)

pred_rf <- predict(model_logistic_cv$finalModel,xtest,type = 'response')
table(pred_rf>0.3,xtest$target)

```

## Gradient Boosting Machine (using Cross-Validation)

```{r, message=FALSE, warning=FALSE}

set.seed(123)
fitControl = trainControl(method="cv", number=10, returnResamp = "all",allowParallel = TRUE)

model_gbm = train(target~., data=balanced.data, method="gbm",distribution="bernoulli", trControl=fitControl, verbose=F, tuneGrid=data.frame(.n.trees=5000, .shrinkage=0.1, .interaction.depth=1, .n.minobsinnode=1))

pred_gbm <- predict(model_gbm,xtest,type = 'prob')

table(pred_gbm$'1'>0.2,xtest$target)

stopCluster(cluster)
registerDoSEQ()

```

## AdaBoost 

```{r, message=FALSE, warning=FALSE}

model_ada = ada(formula = target ~ .,data=balanced.data ,iter=10)

pred_ada <- predict(model_ada,xtest,type = 'prob')

table(pred_ada[,2]>0.2,xtest$target)
```

## Neural Network 
```{r, message=FALSE, warning=FALSE}

# Neural net

balanced.data2 <- SMOTE(target ~., xtrain, perc.over = 4800, k = 5, perc.under = 2400)


y_train <- as.numeric(balanced.data2$target) %>% as.matrix()
y_test <- as.numeric(xtest$target) %>% as.matrix()

x_train <- balanced.data2 %>% select(-c(target)) %>% as.matrix()
x_test <- xtest %>% select(-c(target)) %>% as.matrix()

#defining a neural net model
model_nn <- keras_model_sequential() 
model_nn <- model_nn %>% 
  layer_dense(units = 256, activation = 'tanh', input_shape = c(20)) %>% 
  layer_dropout(rate = 0.4) %>% 
  layer_dense( units= 256, kernel_initializer = "uniform", activation = "tanh") %>%
  layer_dropout(0.1) %>%
  layer_dense(units = 64, activation = 'relu') %>%
  layer_dropout(rate = 0.3) %>%
  layer_dense(units = 1, activation = 'softmax')

model_nn %>% compile(
  loss = 'binary_crossentropy',
  optimizer = optimizer_rmsprop(),
  metrics = c('accuracy')
)

history <- model_nn %>% fit(
  x_train, y_train, 
  epochs = 30, batch_size = 128, 
  validation_split = 0.2
)

pred_model_nn = model_nn %>% predict(x_test)
table(pred_model_nn,xtest$target)

``` 

## Evaluation of Machine Learning Methods
```{r, message=FALSE, warning=FALSE}
#overlapping all the ROC curve

roc(xtest$target,pred_logistic_cv,plot=TRUE,legacy.axes=TRUE, col="#377eb8",
    xlab="False Positive Rate",ylab="True Positive Rate")
plot.roc(xtest$target,pred_ridge, col="#4daf4a",add=TRUE)
plot.roc(xtest$target,pred_rf, col="#FF420E",add=TRUE)
plot.roc(xtest$target,pred_gbm$'1', col="#FFBB00",add=TRUE)
plot.roc(xtest$target,pred_ada[,2], col="#763626",add=TRUE)
plot.roc(xtest$target,pred_model_nn, col="#375E97",add=TRUE)

legend("bottomright",legend=c(
  paste("Logistic regression (LR), AUC = ", format(roc(xtest$target,pred_logistic_cv)$auc,digits=2)), 
  paste("Ridge LR, AUC = ", format(roc(xtest$target,pred_ridge)$auc, digits=2)),
  paste("Random Forest, AUC = ", format(roc(xtest$target,pred_rf)$auc, digits=2)),
  paste("Gradient Boosting, AUC = ", format(roc(xtest$target,pred_gbm$'1')$auc, digits=2)),
  paste("AdaBoost, AUC = ", format(roc(xtest$target,pred_ada[,2])$auc, digits=2)),
  paste("Neural Network, AUC = ", format(roc(xtest$target,pred_model_nn)$auc, digits=2 ))),
            col=c("#377eb8","#4daf4a","#FF420E","#FFBB00","#763626","#375E97"),lwd=4, bg=F, cex=0.75, bty="n")

```


# Survival Analysis

## Survival Analysis: Kaplan Meier (All Individuals)

```{r, message=FALSE, warning=FALSE}

# first step in creating the "time" variable 
# this will be the sequence of months since joining the dataset for each individual
prog = prog %>% group_by(PERSON_ID) %>% mutate(start_year=min(YEAR))
prog = prog %>% mutate(months = (YEAR%%start_year*12) + MONTH)
prog = prog %>% group_by(PERSON_ID) %>% mutate(min_month_year = min(months))
prog = prog %>% mutate(month_seq = months - min_month_year + 1)

# first step in creating the "status" variable
# this will be the month (in the sequence) when the individual overdosed
# it will be NA if the person did not overdose
prog$od_year_month = (as.integer(prog$OVERDOSE_YEAR)%%prog$start_year)*12+as.integer(prog$OVERDOSE_MONTH)
prog$od_seq = prog$od_year_month - prog$min_month_year + 1

# creating the data for survival analysis
# one row per individual
# time is the last month (in sequence) in which the individual is seen in the dataset 
# status is whether or not the event (overdose) occurred
survival_data = prog %>% group_by(PERSON_ID) %>% summarise(time_yearmonth = max(month_seq), od_time = max(od_seq))
survival_data = survival_data %>% mutate(status = if_else(is.na(od_time), 0, 1))
survival_data = survival_data %>% mutate(time = if_else(is.na(od_time), time_yearmonth, od_time))
survival_data = survival_data %>% select(PERSON_ID, status, time)
survival_data = merge(survival_data, dem, key="PERSON_ID")
survival_data = merge(survival_data, age_df %>% select(PERSON_ID, age), key="PERSON_ID")

#plot 1 (overall kaplan meier curve)
km = Surv(survival_data$time, survival_data$status) %>%
  (function(x) survfit(x ~ 1, data=survival_data))(.)
# Kaplan-Meier curve
plot(km, xlab= "Months In System",ylab="P(survive)", mark.time=T)
km

#plot 2 (by gender)
km_gender = survfit(Surv(survival_data$time, survival_data$status) ~ gender, data=survival_data)
plot(km_gender,
     col=c(1:3), mark.time = T); legend("bottomleft", c("Female","Male", "No Data & Other"), col=1:3, lty=c(1,1))
km_gender

#plot 3 (by race but only subsetting to white and black/african-american)
survival_data_subset = survival_data %>% filter(race==c("White", "Black/African-American"))
km_race = survfit(Surv(survival_data_subset$time, survival_data_subset$status) ~ race, data=survival_data_subset)
plot(km_race,
     col=c(1:2), mark.time = T); legend("bottomleft", c("Black/African-American","White"), col=1:2, lty=c(1,1))
km_race

```

## Survival Analysis: Cox Proportional Hazards Model (All Individuals)

```{r, message=FALSE, warning=FALSE}

# Cox model
cm = Surv(survival_data$time, survival_data$status) %>%
  (function(x) coxph(x ~ age + gender, data=survival_data))(.)
cm

# Regularized Cox model
cox_data = survival_data %>% select(-time, -status, -PERSON_ID) %>% as.data.frame() %>% as.matrix()
cox_data = cox_data %>% dummy_cols(c("gender", "race"))
cox_data = cox_data %>% select(-gender, -race) %>% as.data.frame() %>% as.matrix()
lm = glmnet(cox_data, Surv(survival_data$time, survival_data$status), family="cox")
plot(lm)

# Choosing s using cross validation
cvlm = cv.glmnet(cox_data, Surv(survival_data$time, survival_data$status), family="cox")
plot(cvlm)

# showing coefficients of model with minimum lambda
coef(lm, s=cvlm$lambda.min)

# showing coefficients of model with lambda within 1se
coef(lm, s=cvlm$lambda.1se)

```

Need to see if/how this changes if everyone has the same starting point. So, decided to do the survival analysis for a specific cohort i.e. same starting point. We chose cohort==2009 because it has the most amount of data available longitudinally.

## Survival Analysis: Kaplan Meier (2009 Cohort)
```{r, message=FALSE, warning=FALSE}

# filtering to 2009 cohort
prog_cohort2009 = prog %>% filter(start_year==2009)

paste("There are", length(unique(prog_cohort2009$PERSON_ID)), "individuals in the 2009 Cohort")

# creating the datset for survival analysis
survival_data_cohort = prog_cohort2009 %>% group_by(PERSON_ID) %>% summarise(time_yearmonth = max(month_seq), od_time = max(od_seq))
survival_data_cohort = survival_data_cohort %>% mutate(status = if_else(is.na(od_time), 0, 1))
survival_data_cohort = survival_data_cohort %>% mutate(time = if_else(is.na(od_time), time_yearmonth, od_time))
survival_data_cohort = survival_data_cohort %>% select(PERSON_ID, status, time)
survival_data_cohort = merge(survival_data_cohort, dem, key="PERSON_ID")
survival_data_cohort = merge(survival_data_cohort, age_df %>% select(PERSON_ID, age), key="PERSON_ID")

#plot 1 (overall KM)
km_cohort = Surv(survival_data_cohort$time, survival_data_cohort$status) %>%
  (function(x) survfit(x ~ 1, data=survival_data_cohort))(.)
# Kaplan-Meier curve
plot(km_cohort, xlab= "Months In System",ylab="P(survive)", mark.time=T)
km_cohort

#plot 2 (by gender)
km_gender_cohort = survfit(Surv(survival_data_cohort$time, survival_data_cohort$status) ~ gender, data=survival_data_cohort)
plot(km_gender_cohort,
     col=c(1:3), mark.time = T); legend("bottomleft", c("Female","Male", "No Data & Other"), col=1:3, lty=c(1,1))
km_gender_cohort

#plot 3 (by race but only subsetting to white and black/african-american)
survival_data_subset_cohort = survival_data_cohort %>% filter(race==c("White", "Black/African-American"))
km_race_cohort = survfit(Surv(survival_data_subset_cohort$time, survival_data_subset_cohort$status) ~ race,
                         data=survival_data_subset_cohort)
plot(km_race_cohort,
     col=c(1:2), mark.time = T); legend("bottomleft", c("Black/African-American","White"), col=1:2, lty=c(1,1))
km_race_cohort

```

## Survival Analysis: Cox Proportional Hazards Model (2009 Cohort)
```{r, message=FALSE, warning=FALSE}

# Cox model
cm_cohort = Surv(survival_data_cohort$time, survival_data_cohort$status) %>%
  (function(x) coxph(x ~ age + gender, data=survival_data_cohort))(.)
cm_cohort

# Regularized Cox model
cox_data_cohort = survival_data_cohort %>% select(-time, -status, -PERSON_ID) %>% as.data.frame() %>% as.matrix()
cox_data_cohort = cox_data_cohort %>% dummy_cols(c("gender", "race"))
cox_data_cohort = cox_data_cohort %>% select(-gender, -race) %>% as.data.frame() %>% as.matrix()
lm_cohort = glmnet(cox_data_cohort, Surv(survival_data_cohort$time, survival_data_cohort$status), family="cox")
plot(lm_cohort)

# Choosing s with cross-validation
cvlm_cohort = cv.glmnet(cox_data_cohort, Surv(survival_data_cohort$time, survival_data_cohort$status), family="cox")
plot(cvlm_cohort)

# showing coefficients with minimum lambda
coef(lm_cohort, s=cvlm$lambda.min)

# showing coefficients with lambda at 1se
coef(lm_cohort, s=cvlm$lambda.1se)

```